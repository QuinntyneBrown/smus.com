<!doctype html>
<head>
  <title>Welcome | Boris Smus</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="">

  <!-- Icons -->
  <link rel="icon" type="image/x-icon" href="/static/icons/favicon.ico" />
  <link rel="apple-touch-icon" href="/static/icons/apple-touch-icon.png">

  <!-- Styles -->
  <link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz:700|PT+Sans|Inconsolata' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/static/stylesheets/screen.css" type="text/css" media="screen" charset="utf-8">

  <!-- Feed -->
  <link href="http://feeds.feedburner.com/smuscom" rel="alternate" title="Boris Smus" type="application/atom+xml"/>
</head>
<body>
  <header>
    <span class="left">
      <a href="/" class="name">Boris Smus</a>
    </span>
    <span class="right">
      <a href="/projects/">Projects</a>
      <a href="/about/">About</a>
      <a href="/archive/posts/">Archives</a>
    </span>
  </header>

  <div id="main">
    <section id="articles">
      

<article class="type-post">
  <h1><a href="/spatial-audio-web-vr">Spatial Audio and Web VR</a></h1>
  <div class="subtitle">
  
  <time>Published on 19 March 2015</time>
  
  
  </div>
  <p>
    <p>Last summer I visited Austria, the capital of classical music. I had the
pleasure of hearing the <a href="http://en.wikipedia.org/wiki/Vespro_della_Beata_Vergine">Vespers of 1610</a> in the great
<a href="http://goo.gl/e3WBB2">Salzburger Dom (photosphere)</a>. The most memorable part of
the piece was that the soloists moved between movements, so their voices
and instruments emanated from surprising parts of the great hall.
Inspired, I returned to the west coast and eventually came around to
building a spatial audio prototypes like this one:</p>

<p><a href="http://borismus.github.io/moving-music"><img src="/spatial-audio-web-vr/collage_small.jpg" alt="Screenshot of a demo" /></a></p>

<p>Spatial audio is an important part of any good VR experience, since the
more senses we simulate, the more compelling it feels to our sense
fusing mind. WebVR, WebGL, and WebAudio all act as complementary specs
to enable this necessary experience. As you would expect, because it
uses the <a href="https://github.com/borismus/webvr-boilerplate">WebVR boilerplate</a>, this demo can be viewed on
mobile, desktop, in Cardboard or an Oculus Rift. In all cases, you will
need headphones :)</p>


  </p>
  
  <a href="/spatial-audio-web-vr" class="readmore" title="Continue reading..."></a>
  
</article>

<article class="type-post">
  <h1><a href="/responsive-vr">Responsive WebVR, Headset Optional</a></h1>
  <div class="subtitle">
  
  <time>Published on 02 February 2015</time>
  
  
  </div>
  <p>
    <p>VR on the web threatens to cleave the web platform in twain, like mobile
did before it. The solution then and the solution now is <a href="http://en.wikipedia.org/wiki/Responsive_web_design">Responsive Web
Design</a>, which websites to scale well for all form factors.
Similarly, for VR to succeed on the web, we need to figure out how to
make VR experiences that work both in any VR headset, and also without a
VR headset at all.</p>

<p><img src="/responsive-vr/hmds.png" alt="Various head mounted displays." /></p>

<p><a href="https://github.com/borismus/webvr-boilerplate">WebVR boilerplate</a> is a new starting point for building
responsive web VR experiences that work on popular VR headsets and
degrace gracefully on other platforms. Check out a couple of demos, <a href="http://borismus.github.io/webvr-boilerplate/">a
simple one</a> and one <a href="http://borismus.github.io/sechelt">ported from MozVR</a>.</p>


  </p>
  
  <a href="/responsive-vr" class="readmore" title="Continue reading..."></a>
  
</article>

<article class="type-post">
  <h1><a href="/web-sensor-api">Web Sensor API: Raw and Uncut</a></h1>
  <div class="subtitle">
  
  <time>Published on 13 November 2014</time>
  
  
  </div>
  <p>
    <p>Sensors found in smartphones define the mobile experience. GPS and the
magnetometer enable the fluid experience of maps; motion sensing enables
activity recognition and games, and of course the camera and microphone
allow whole categories of rich media applications. Beyond these now
obvious examples, sensors can also enable clever inventions, such as
<a href="http://www.cycloramic.com/">Cycloramic</a>, which used the vibrator motor in iPhones (4 and 5) to
rotate the phone and take a panorama, <a href="https://play.google.com/store/apps/details?id=com.runtastic.android.pushup.pro">pushup counters</a> which
use the proximity sensor to count repetitions, and <a href="https://play.google.com/store/apps/details?id=com.carrotpop.www.smth">Send Me To
Heaven</a>, which uses the accelerometer to determine flight time of
a phone thrown vertically as high as possible. I've had some experience
using and abusing sensors too, most recently for the <a href="http://smus.com/talk/2014/io14/">Cardboard magnet
button</a>.</p>

<p><video src="/web-sensor-api/web_sensor_api.webm" autoplay muted loop controls style="height: auto; width: 100%;"></video></p>

<p>However, over the last couple of years, I've had to step away from the
web as a development platform, in part because of the poor state of
sensor APIs.  In this post, I will describe some of the problems, take a
look at sensor APIs on iOS and Android, and suggest a solution in the
spirit of the <a href="https://extensiblewebmanifesto.org/">extensible web manifesto</a>.</p>


  </p>
  
  <a href="/web-sensor-api" class="readmore" title="Continue reading..."></a>
  
</article>

<article class="type-post">
  <h1><a href="/uist-2014">UIST 2014 Highlights</a></h1>
  <div class="subtitle">
  
  <time>Published on 14 October 2014</time>
  
  
  </div>
  <p>
    <p>This year's <a href="http://www.acm.org/uist/uist2014/">UIST</a> was held in Waikiki, Honolulu, the undisputed
tourist capital of Hawaii. I've stuck to my now three year old habit of
taking notes and <a href="http://smus.com/uist-2013">posting my favorite work</a>. Since last year,
the conference has grown an extra track. The split was generally OK for
me, with my track mostly dedicated to user interface innovation
(sensors, etc) and another more concerned with crowdsourcing,
visualization, and more traditional UIs.</p>

<p>My overall feeling was that the research was mostly interesting from a
tech perspective, but focused on solving the wrong problem. For example,
at least 5 papers/posters/demos were focused on typing on smartwatches.
The keynotes were very thought provoking, especially when juxtaposed
with one another.</p>


  </p>
  
  <a href="/uist-2014" class="readmore" title="Continue reading..."></a>
  
</article>

<article class="type-link">
  <h1><a href="http://sonify.psych.gatech.edu/~ben/references/gaver_the_sonicfinder_an_interface_that_uses_auditory_icons.pdf">Complementary modes of sound and vision</a></h1>
  <div class="subtitle">
  
  <time>Linked on 08 September 2014</time>
  
  
  <a class="permalink" href="/link/2014/9/8/complementary-modes-of-sound-and-vision"></a>
  
  </div>
  <p>
    <p>On the bus-ride home, I'm was reading a paper from 1989, written by Bill Gaver at Apple, after working on SonicFinder, a very early version of Finder with copious amounts of user interface sounds.</p>

<p>To motivate the application of sounds in user interfaces, he presents this gem of a table on audition and vision, and how they relate to our perception of time and space:</p>

<p><img src="/link/2014/9/8/complementary-modes-of-sound-and-vision/timespace-soundvision.jpg" alt="Sound and vision, in time and space" /></p>

  </p>
  
</article>

<article class="type-link">
  <h1><a href="http://dantepfer.com/blog/?p=277">On Rhythm and Pitch</a></h1>
  <div class="subtitle">
  
  <time>Linked on 06 September 2014</time>
  
  
  <a class="permalink" href="/link/2014/9/6/on-rhythm-and-pitch"></a>
  
  </div>
  <p>
    <p>Dan Tepfer on the interesting relationship between rhythm and pitch, at first glance completely distinct musical phenomena. The fascinating thing is that the two are actually quite related. Fundamentally, it's a question of frequency. Slow repetition (low frequency) is perceived as rhythm, while fast repetition (high frequency) is perceived as pitch, by apparently distinct subsystems. Quoth Dan:</p>

<blockquote>
  <p>For slow things, our consciousness distinguishes individual events and interprets them as what we call “rhythm”, such as the child tapping on her knees. For very fast things (like when the taps get very close together), our consciousness isn’t fast enough to distinguish the individual events, and our pitch hearing kicks in, guided by those tiny hairs in our cochlea, each one specialized in resonating at a certain pitch.</p>
</blockquote>

  </p>
  
</article>

<article class="type-talk">
  <h1><a href="https://www.youtube.com/watch?v=DFog2gMnm44">Cardboard: VR for Android (Google I/O 2014)</a></h1>
  <div class="subtitle">
  
  <time>Presented on 26 June 2014</time>
  
  
  <a class="permalink" href="/talk/2014/io14"></a>
  
  </div>
  <p>
    <p><a href="https://twitter.com/dav_cz">David Coz</a>, <a href="http://plagemann.net/">Christian Plagemann</a> and I had the
honor of giving a talk at I/O a few weeks ago, introducing Cardboard, a
simple way to turn your smartphone into a VR headset. Watch the <a href="https://www.youtube.com/watch?v=DFog2gMnm44">video
here</a>.</p>

<p>I'm especially excited about two cardboard-related things. Firstly, the
magnet-based button, which I worked on, was generally liked and deemed
clever! I'm hoping to write more about the technical details of this in
the future, but <a href="http://techcrunch.com/2014/06/25/hands-on-with-googles-incredibly-clever-cardboard-virtual-reality-headset/">this techcrunch summary</a> was music to my ears,
thanks guys!</p>

<p><img src="/talk/2014/io14/click-click.gif" style="float: right; margin-left: 1em;"/></p>

<blockquote>
  <p>The magnet slides within its groove, then automatically slips back
  into a place because of another magnet on opposite side. Your phone is
  able to sense the magnet’s movement, allowing it to act as a
  ridiculously clever little button. Yeesh.</p>
</blockquote>

<p><br style="clear: both;"/></p>

<p>Secondly, we've released the <a href="https://github.com/googlesamples/cardboard">VR toolkit on github</a> for you to
experiment with. The whole thing will be fully open sourced soon, but
for the time being, a JAR file, javadoc, and a sample application are
provided on the <a href="https://developers.google.com/cardboard/overview">Cardboard developer site</a>.</p>

  </p>
  
</article>

<article class="type-post">
  <h1><a href="/spectrogram-and-oscillator">Spectrogram and Oscillator</a></h1>
  <div class="subtitle">
  
  <time>Published on 09 June 2014</time>
  
  
  </div>
  <p>
    <p>A live-input spectrogram written using <a href="http://polymer-project.org">Polymer</a> using the <a href="http://webaudioapi.com">Web
Audio API</a>.</p>

<p><img src="/spectrogram-and-oscillator/screenshot.png" alt="Screenshot of spectrogram" /></p>

<p>If you're running Chrome or Firefox, <a href="http://borismus.github.io/spectrogram">see it in action</a>. Once the
spectrogram is running, see if you can make a pattern with your speech
or by whistling. You can also click anywhere on the page to turn on the
oscillator. For a mind-blowing effect, <a href="https://www.youtube.com/watch?v=M9xMuPWAZW8&amp;t=5m30s">load this</a> in a parallel
tab.</p>


  </p>
  
  <a href="/spectrogram-and-oscillator" class="readmore" title="Continue reading..."></a>
  
</article>

<article class="type-post">
  <h1><a href="/addressable-apps">Addressable apps</a></h1>
  <div class="subtitle">
  
  <time>Published on 21 May 2014</time>
  
  
  </div>
  <p>
    <p>It is human nature to create taxonomies for everything: people, places,
and things.  Without such a system of reference, we become lost and
disoriented.  Imagine your city with street names and addresses blanked
out. Finding your favorite cafe, meeting up with your friend on the
weekend, even locating your own parked car would become incredibly
difficult. Travel outside your city would become far more
challenging.</p>

<p>The web's defining property is addressability. URLs on the web are like
street names and addresses in the physical world. This makes sharing
and cross-linking easy. Non-web platforms are a little bit like our
city with blanked out street names and addresses. There's no good
way of talking about where you currently are, or how to get somewhere
else. These platforms typically give users a crutch to help with the
issue, such as a share button or dialog. But these create an
inherently inferior experience, since addressability is no longer
built-in. Addressability becomes a burden on the app developer, and
as a result, the platform is no longer navigable.</p>

<p>In light of the success of Android and iOS, and given a potential
explosion in new types of lower power computing (wearables, IoT, etc),
it's unclear if <a href="http://smus.com/ebb-of-the-web/">browsers will be as ubiquitous</a> as they are
today (at least in the near term). I'm very interested in seeing if and
how non-web platforms can embrace URLs.  How closely coupled are URLs to
HTML, and do they make sense without a presentation layer?</p>


  </p>
  
  <a href="/addressable-apps" class="readmore" title="Continue reading..."></a>
  
</article>

<article class="type-post">
  <h1><a href="/ebb-of-the-web">The Ebb of the Web</a></h1>
  <div class="subtitle">
  
  <time>Published on 15 April 2014</time>
  
  
  </div>
  <p>
    <p>Tech pundits like to lament that the web has <a href="http://cdixon.org/2014/04/07/the-decline-of-the-mobile-web/">no viable
future</a>, while web idealists hold that in fact the web is
totally fine, with a "too big to fail" <a href="http://schepers.cc/the-recline-of-the-mobile-web">sort of attitude</a>.</p>

<p>At the root of this disagreement are poorly defined terms. The web can
mean many different things to different people. Though it started from a
pretty abstract notion of a series of interlinked documents, it has now
evolved to refer to a very specific technology stack of hyperlinked HTML
documents styled with CSS, enhanced with JavaScript, all served on top
of HTTP. In light of an increasing movement away from desktop-style
computing, we've seen a big shift away from the web in mobile platforms. </p>

<p>Let's take apart this gob of web technology in light of the increasingly
complex landscape of computing and try to make sense of what the web is
and where it's going.</p>

<p><img src="/ebb-of-the-web/webiness.png" alt="A framework for webiness" /></p>


  </p>
  
  <a href="/ebb-of-the-web" class="readmore" title="Continue reading..."></a>
  
</article>


<a class="older-posts" href="/archive/posts">Older posts &rarr;</a>

    </section>
    <aside>
      <img src="/static/images/me.jpg" alt="Headshot of Author" title="Headshot of Author">
      <p>
        I'm Boris Smus, a software engineer and UI prototyper from
        Vancouver, Canada. I currently live in San Francisco and work on
        Chrome related things.
        <a href="/about/" class="readmore"></a>
      </p>
    </aside>
  </div>

  <div id="push"></div>

  <footer>
    <p>
      &copy; 2008 - 2015 Boris Smus<br>
      Powered by <a href="/site/">Lightning</a>
    </p>

    <ul id="social-links">
      <a href="http://feeds.feedburner.com/smuscom" class="social rss" title="RSS" rel="external me">RSS</a>
      <a href="https://github.com/borismus" class="social github" title="GitHub" rel="external me">GitHub</a>
      <a href="https://profiles.google.com/boris.smus" rel="author" class="social plus" title="Google Plus" rel="external me">Google Plus</a>
      <a href="https://twitter.com/borismus" class="social twitter" title="Twitter" rel="external me">Twitter</a>
    </ul>
  </footer>


  <script src="/static/javascripts/highlight.pack.js"></script>
  <script>
    // Syntax highlighting for code.
    hljs.tabReplace = '  ';
    hljs.initHighlightingOnLoad();
  </script>
  <script>
    // Google Analytics.
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-17930798-22', 'smus.com');
    ga('require', 'displayfeatures');
    ga('send', 'pageview');
  </script>
  <script src="//cdn.webglstats.com/stat.js" defer="defer" async="async"></script>
  <script src="/lightning_error.js"></script>
</body>